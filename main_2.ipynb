{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a89feff2",
   "metadata": {},
   "source": [
    "# Recommender system - final project\n",
    "## 1. Exploratory data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a1b9d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from pandas.api.types import CategoricalDtype\n",
    "import random\n",
    "from scipy.sparse import coo_matrix\n",
    "import scipy.sparse as sparse\n",
    "from scipy.sparse.linalg import spsolve\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "243386aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>15085</td>\n",
       "      <td>2020-12-18 21:26:47.986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13</td>\n",
       "      <td>18626</td>\n",
       "      <td>2020-03-13 19:36:15.507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18</td>\n",
       "      <td>24911</td>\n",
       "      <td>2020-08-26 19:20:32.049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19</td>\n",
       "      <td>12534</td>\n",
       "      <td>2020-11-02 17:16:45.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24</td>\n",
       "      <td>13226</td>\n",
       "      <td>2020-02-26 18:27:44.114</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   session_id  item_id                     date\n",
       "0           3    15085  2020-12-18 21:26:47.986\n",
       "1          13    18626  2020-03-13 19:36:15.507\n",
       "2          18    24911  2020-08-26 19:20:32.049\n",
       "3          19    12534   2020-11-02 17:16:45.92\n",
       "4          24    13226  2020-02-26 18:27:44.114"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The purchase that happened at the end of the session. One purchase per session.\n",
    "\n",
    "train_purchases = pd.read_csv(\"data/train_purchases.csv\")\n",
    "train_purchases.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d1cba69",
   "metadata": {},
   "source": [
    "The items that were viewed in a session. The \"date\" column is a timestamp to miliseconds. A session is equal to a day, \n",
    "so a session is one user's activity on one day. The session goes up to and not including the first time the user viewed \n",
    "the item that they bought in the end. The last item in the session will be the last item viewed before viewing the item that they bought. \n",
    "To find they item they bought link to train_purchases.csv on session_id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeea2f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sessions = pd.read_csv(\"data/train_sessions.csv\")\n",
    "train_sessions.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddf11266",
   "metadata": {},
   "source": [
    "The label data of items. A feature_category_id represents an aspect of the item such as \"colour\", the feature_value_id is the value for that aspect, \n",
    "e.g. \"blue\". Some items may not share many feature_cateogry_ids if they different types of items, for example trousers will share almost \n",
    "nothing with shirts. Even things like colour will not be shared, the colour aspect for trousers and shirts are two different feature_category_ids."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e86bd31",
   "metadata": {},
   "source": [
    "## 2. Matrix factorization with implicit feedback"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e150a8a",
   "metadata": {},
   "source": [
    "### Create training/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "436e59e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_purchases['action'] = np.repeat(50.0, train_purchases.shape[0])\n",
    "train_sessions['action'] = np.ones(train_sessions.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87eda490",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = train_purchases.append(train_sessions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "389a3cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values('session_id', inplace=True)\n",
    "df.drop('date', axis=1, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5cb9a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "users = df['session_id'].unique()\n",
    "random.shuffle(users)\n",
    "users_train = users[:900000]\n",
    "users_test = users[900000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea200dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df[df['session_id'].isin(users_train)]\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f743ffb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = train_sessions[train_sessions['session_id'].isin(users_test)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "680e4bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.drop(['action', 'date'], axis=1, inplace=True)\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3abccf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "415e5c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.columns = ['user', 'item', 'rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce783f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.groupby(['user', 'item']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f8ad2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.sort_values('rating', ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d4b136",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de9faea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['confidence'] = df_train['rating'].apply(lambda x: 1 + 40 * x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "939e2c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.drop('rating', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14456f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['preference'] = df_train['confidence'].apply(lambda x: 0 if x == 41.0 else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b24e70c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.columns = ['user', 'item']\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9055914f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matrix factorization test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f387cac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.drop('preference', axis=1, inplace=True)\n",
    "df_train.columns = ['user_id', 'item_id', 'rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195f83fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "item_split = list(df_train.item_id.unique())[:int(np.round(len(df_train.item_id.unique()) * 0.03))]\n",
    "\n",
    "df_train = df_train[df_train['item_id'].isin(item_split)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa6abd2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ebcb21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a sparse matrix\n",
    "\n",
    "users = df_train[\"user_id\"].unique()\n",
    "items = df_train[\"item_id\"].unique()\n",
    "\n",
    "# Create indices for users and items\n",
    "user_cat = CategoricalDtype(categories=sorted(users), ordered=True)\n",
    "item_cat = CategoricalDtype(categories=sorted(items), ordered=True)\n",
    "user_index = df_train[\"user_id\"].astype(user_cat).cat.codes\n",
    "item_index = df_train[\"item_id\"].astype(item_cat).cat.codes\n",
    "\n",
    "# Conversion via COO matrix\n",
    "coo = coo_matrix((df_train[\"rating\"], (user_index, item_index)), shape=(len(users), len(items)))\n",
    "sparse_item_user = coo.tocsr()\n",
    "coo = coo_matrix((df_train[\"rating\"], (item_index, user_index)), shape=(len(items), len(users)))\n",
    "sparse_user_item = coo.tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb63703",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.sparse as sparse\n",
    "from scipy.sparse.linalg import spsolve\n",
    "import random\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import implicit # The Cython library\n",
    "\n",
    "# Initialize the als model and fit it using the sparse item-user matrix\n",
    "model = implicit.als.AlternatingLeastSquares(factors=20, regularization=0.1, iterations=20)\n",
    "\n",
    "# Calculate the confidence by multiplying it by our alpha value.\n",
    "alpha_val = 15\n",
    "data_conf = (sparse_item_user * alpha_val).astype('double')\n",
    "\n",
    "# Fit the model\n",
    "model.fit(data_conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "802fba8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend(user_id, sparse_user_item, user_vecs, item_vecs, num_items=10):\n",
    "    \"\"\"The same recommendation function we used before\"\"\"\n",
    "\n",
    "    user_interactions = sparse_user_item[user_id,:].toarray()\n",
    "\n",
    "    user_interactions = user_interactions.reshape(-1) + 1\n",
    "    user_interactions[user_interactions > 1] = 0\n",
    "\n",
    "    rec_vector = user_vecs[user_id,:].dot(item_vecs.T).toarray()\n",
    "\n",
    "    min_max = MinMaxScaler()\n",
    "    rec_vector_scaled = min_max.fit_transform(rec_vector.reshape(-1,1))[:,0]\n",
    "    recommend_vector = user_interactions * rec_vector_scaled\n",
    "\n",
    "    item_idx = np.argsort(recommend_vector)[::-1][:num_items]\n",
    "\n",
    "    items = []\n",
    "    scores = []\n",
    "\n",
    "    for idx in item_idx:\n",
    "        items.append(data.item.loc[data.item_id == idx].iloc[0])\n",
    "        scores.append(recommend_vector[idx])\n",
    "\n",
    "    recommendations = pd.DataFrame({'items': items, 'score': scores})\n",
    "\n",
    "    return recommendations\n",
    "\n",
    "# Get the trained user and item vectors. We convert them to \n",
    "# csr matrices to work with our previous recommend function.\n",
    "user_vecs = sparse.csr_matrix(model.user_factors)\n",
    "item_vecs = sparse.csr_matrix(model.item_factors)\n",
    "\n",
    "# Create recommendations for user with id 2025\n",
    "user_id = 3\n",
    "\n",
    "recommendations = recommend(user_id, sparse_user_item, user_vecs, item_vecs)\n",
    "\n",
    "# print(recommendations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe4e5f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124697a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = NearestNeighbors(metric='cosine', algorithm='brute', n_neighbors=50)\n",
    "knn.fit(csr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbcfea3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_users_test = df_test['user'].unique()[:100]\n",
    "answers = []\n",
    "\n",
    "for x in range(len(df_users_test)):\n",
    "\n",
    "    filter1 = df_test[df_test['user'] == df_users_test[x]]['item']\n",
    "    filter1 = filter1.tolist()\n",
    "    filter1 = filter1[:20]\n",
    "    #print(\"Items liked by user \",user,\": \",filter1)\n",
    "\n",
    "    distances1=[]\n",
    "    indices1=[]\n",
    "    for i in filter1:\n",
    "        distances , indices = knn.kneighbors(csr[i],n_neighbors=10)\n",
    "        indices = indices.flatten()\n",
    "        indices= indices[1:]\n",
    "        indices1.extend(indices)\n",
    "\n",
    "    #print(\"Items to be recommended: \",indices1)\n",
    "    #print(len(df_users_test) - x)\n",
    "    answers.append(indices1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2132858",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d58f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def implicit_als(sparse_data, alpha_val=40, iterations=10, lambda_val=0.1, features=10):\n",
    " \n",
    "    \"\"\" Implementation of Alternating Least Squares with implicit data. We iteratively\n",
    "    compute the user (x_u) and item (y_i) vectors using the following formulas:\n",
    " \n",
    "    x_u = ((Y.T*Y + Y.T*(Cu - I) * Y) + lambda*I)^-1 * (X.T * Cu * p(u))\n",
    "    y_i = ((X.T*X + X.T*(Ci - I) * X) + lambda*I)^-1 * (Y.T * Ci * p(i))\n",
    " \n",
    "    Args:\n",
    "        sparse_data (csr_matrix): Our sparse user-by-item matrix\n",
    " \n",
    "        alpha_val (int): The rate in which we'll increase our confidence\n",
    "        in a preference with more interactions.\n",
    " \n",
    "        iterations (int): How many times we alternate between fixing and \n",
    "        updating our user and item vectors\n",
    " \n",
    "        lambda_val (float): Regularization value\n",
    " \n",
    "        features (int): How many latent features we want to compute.\n",
    "    \n",
    "    Returns:     \n",
    "        X (csr_matrix): user vectors of size users-by-features\n",
    "        \n",
    "        Y (csr_matrix): item vectors of size items-by-features\n",
    "     \"\"\"\n",
    "\n",
    "    # Calculate the foncidence for each value in our data\n",
    "    confidence = sparse_data * alpha_val\n",
    "    \n",
    "    # Get the size of user rows and item columns\n",
    "    user_size, item_size = sparse_data.shape\n",
    "    \n",
    "    # We create the user vectors X of size users-by-features, the item vectors\n",
    "    # Y of size items-by-features and randomly assign the values.\n",
    "    X = sparse.csr_matrix(np.random.normal(size = (user_size, features)))\n",
    "    Y = sparse.csr_matrix(np.random.normal(size = (item_size, features)))\n",
    "    \n",
    "    #Precompute I and lambda * I\n",
    "    X_I = sparse.eye(user_size)\n",
    "    Y_I = sparse.eye(item_size)\n",
    "    \n",
    "    I = sparse.eye(features)\n",
    "    lI = lambda_val * I\n",
    "    \n",
    "\n",
    "    # Start main loop. For each iteration we first compute X and then Y\n",
    "    for i in range(iterations):\n",
    "        print('iteration %d of %d' % (i+1, iterations))\n",
    "        \n",
    "        # Precompute Y-transpose-Y and X-transpose-X\n",
    "        yTy = Y.T.dot(Y)\n",
    "        xTx = X.T.dot(X)\n",
    "\n",
    "        # Loop through all users\n",
    "        for u in range(user_size):\n",
    "\n",
    "            # Get the user row.\n",
    "            u_row = confidence[u,:].toarray() \n",
    "\n",
    "            # Calculate the binary preference p(u)\n",
    "            p_u = u_row.copy()\n",
    "            p_u[p_u != 0] = 1.0\n",
    "\n",
    "            # Calculate Cu and Cu - I\n",
    "            CuI = sparse.diags(u_row, [0])\n",
    "            Cu = CuI + Y_I\n",
    "\n",
    "            # Put it all together and compute the final formula\n",
    "            yT_CuI_y = Y.T.dot(CuI).dot(Y)\n",
    "            yT_Cu_pu = Y.T.dot(Cu).dot(p_u.T)\n",
    "            X[u] = spsolve(yTy + yT_CuI_y + lI, yT_Cu_pu)\n",
    "\n",
    "    \n",
    "        for i in range(item_size):\n",
    "\n",
    "            # Get the item column and transpose it.\n",
    "            i_row = confidence[:,i].T.toarray()\n",
    "\n",
    "            # Calculate the binary preference p(i)\n",
    "            p_i = i_row.copy()\n",
    "            p_i[p_i != 0] = 1.0\n",
    "\n",
    "            # Calculate Ci and Ci - I\n",
    "            CiI = sparse.diags(i_row, [0])\n",
    "            Ci = CiI + X_I\n",
    "\n",
    "            # Put it all together and compute the final formula\n",
    "            xT_CiI_x = X.T.dot(CiI).dot(X)\n",
    "            xT_Ci_pi = X.T.dot(Ci).dot(p_i.T)\n",
    "            Y[i] = spsolve(xTx + xT_CiI_x + lI, xT_Ci_pi)\n",
    "\n",
    "    return X, Y"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
